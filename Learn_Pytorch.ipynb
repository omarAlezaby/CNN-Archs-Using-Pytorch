{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Learn_Pytorch.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "VTBa31GJX_dA",
        "colab_type": "code",
        "outputId": "b2fbfd0c-c533-4fe7-92b2-d54eb8baff63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        }
      },
      "cell_type": "code",
      "source": [
        "# install Pytorch\n",
        "\n",
        "!pip3 install torch torchvision"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/60/66415660aa46b23b5e1b72bc762e816736ce8d7260213e22365af51e8f9c/torch-1.0.0-cp36-cp36m-manylinux1_x86_64.whl (591.8MB)\n",
            "\u001b[K    100% |████████████████████████████████| 591.8MB 28kB/s \n",
            "tcmalloc: large alloc 1073750016 bytes == 0x6175c000 @  0x7f89735532a4 0x591a07 0x5b5d56 0x502e9a 0x506859 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x502540 0x502f3d 0x507641\n",
            "\u001b[?25hCollecting torchvision\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/0d/f00b2885711e08bd71242ebe7b96561e6f6d01fdb4b9dcf4d37e2e13c5e1/torchvision-0.2.1-py2.py3-none-any.whl (54kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 22.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
            "Collecting pillow>=4.1.1 (from torchvision)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/e3/217dfd0834a51418c602c96b110059c477260c7fee898542b100913947cf/Pillow-5.4.0-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 2.0MB 5.0MB/s \n",
            "\u001b[?25hInstalling collected packages: torch, pillow, torchvision\n",
            "  Found existing installation: Pillow 4.0.0\n",
            "    Uninstalling Pillow-4.0.0:\n",
            "      Successfully uninstalled Pillow-4.0.0\n",
            "Successfully installed pillow-5.4.0 torch-1.0.0 torchvision-0.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "njTjz5hkYNpc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, sampler\n",
        "\n",
        "import torchvision.datasets as dset \n",
        "import torchvision.transforms as transform "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vjmo9MTXK2r1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "6ea7784f-261e-400d-9577-dc2f514e7472"
      },
      "cell_type": "code",
      "source": [
        "# preprocess data\n",
        "\n",
        "class CSampler(sampler.Sampler):\n",
        "  \n",
        "  def __init__(self, num_samp, start=0):\n",
        "    self.num_samp  = num_samp\n",
        "    self.start = start\n",
        "    \n",
        "    \n",
        "  def __iter__(self):\n",
        "    \n",
        "    return iter(range(self.start, self.start + self.num_samp))\n",
        "  \n",
        "  \n",
        "  def __Len__(self):\n",
        "    \n",
        "    return self.num_samp \n",
        "\n",
        "\n",
        "\n",
        "#data agumantation to the train data\n",
        "train_transform = transform.Compose([\n",
        "    transform.RandomHorizontalFlip(),\n",
        "    transform.RandomRotation(15),\n",
        "    transform.ToTensor()\n",
        "])\n",
        "\n",
        "# For test data\n",
        "\n",
        "test_transform = transform.Compose([\n",
        "    transform.ToTensor()\n",
        "])\n",
        "\n",
        "\n",
        "num_tarin = 49000\n",
        "num_valid = 1000\n",
        "\n",
        "\n",
        "CIFAR10_train = dset.CIFAR10(root = './data', train = True, download = True, \n",
        "                             transform=train_transform)\n",
        "\n",
        "\n",
        "train_loder = DataLoader(CIFAR10_train, batch_size=128, sampler=CSampler(num_tarin, 0))\n",
        "\n",
        "CIFAR10_val = dset.CIFAR10(root = './data', train = True, download = True, \n",
        "                             transform=test_transform)\n",
        "\n",
        "\n",
        "val_loder = DataLoader(CIFAR10_val, batch_size=128, sampler=CSampler(num_valid, num_tarin))\n",
        "\n",
        "\n",
        "CIFAR10_test = dset.CIFAR10(root = './data', train = False, download = True, \n",
        "                             transform=test_transform)\n",
        "\n",
        "\n",
        "test_loder = DataLoader(CIFAR10_test, batch_size=128)\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DUxUTkxlU-B6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e631e6de-9583-4656-df57-6d0e173ca8b2"
      },
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "OIoVJ8I-yjOG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# VGG16 Arch\n",
        "\n",
        "class Flatten(nn.Module):\n",
        "  def forward(self, x):\n",
        "    N, C, H, W = x.size()\n",
        "    return x.view(N, -1)\n",
        "  \n",
        "  \n",
        "VGG16_model = nn.Sequential(# First Block 64\n",
        "                            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
        "                            nn.BatchNorm2d(64),\n",
        "                            nn.ReLU(inplace=True),\n",
        "                            \n",
        "                            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
        "                            nn.BatchNorm2d(64),\n",
        "                            nn.ReLU(inplace=True),\n",
        "                            \n",
        "                            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "                            \n",
        "                            # Second block 128\n",
        "                            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "                            nn.BatchNorm2d(128),\n",
        "                            nn.ReLU(inplace=True),\n",
        "                            \n",
        "                            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
        "                            nn.BatchNorm2d(128),\n",
        "                            nn.ReLU(inplace=True),\n",
        "                            \n",
        "                            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "                            \n",
        "                            #third block 256\n",
        "                            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
        "                            nn.BatchNorm2d(256),\n",
        "                            nn.ReLU(inplace=True),\n",
        "                            \n",
        "                            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
        "                            nn.BatchNorm2d(256),\n",
        "                            nn.ReLU(inplace=True),\n",
        "                            \n",
        "                            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
        "                            nn.BatchNorm2d(256),\n",
        "                            nn.ReLU(inplace=True),\n",
        "                            \n",
        "                            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "                            \n",
        "                            #forth block 512\n",
        "                            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
        "                            nn.BatchNorm2d(512),\n",
        "                            nn.ReLU(inplace=True),\n",
        "                            \n",
        "                            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
        "                            nn.BatchNorm2d(512),\n",
        "                            nn.ReLU(inplace=True),\n",
        "                            \n",
        "                            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
        "                            nn.BatchNorm2d(512),\n",
        "                            nn.ReLU(inplace=True),\n",
        "                            \n",
        "                            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "                            \n",
        "                            #fifth block 512\n",
        "                            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
        "                            nn.BatchNorm2d(512),\n",
        "                            nn.ReLU(inplace=True),\n",
        "                            \n",
        "                            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
        "                            nn.BatchNorm2d(512),\n",
        "                            nn.ReLU(inplace=True),\n",
        "                            \n",
        "                            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
        "                            nn.BatchNorm2d(512),\n",
        "                            nn.ReLU(inplace=True),\n",
        "                            \n",
        "                            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "                            \n",
        "                            # Flatte the output/ 512*1*1\n",
        "                            Flatten(),\n",
        "                            # Classefier\n",
        "                            \n",
        "                            nn.Linear(512, 10)\n",
        "                           )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j5swFUn3AjYU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dtype = torch.cuda.FloatTensor\n",
        "\n",
        "VGG16_model = VGG16_model.type(dtype)\n",
        "\n",
        "lss_fun = nn.CrossEntropyLoss().type(dtype)\n",
        "optimizer = optim.Adam(VGG16_model.parameters(), lr=1e-3, weight_decay=5e-4)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=.1) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R9OTVPUCFagH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# function to train the model for 1 epoch on the data set\n",
        "def train(model, loder, lss_fn, optmizer, epoch):\n",
        "  print('epoch number %d' % (epoch))\n",
        "  model.train()\n",
        "  epoch_loss = 0.0\n",
        "  epoch_acc = 0.0\n",
        "  num_itr = 0\n",
        "  for idx, (x, y) in enumerate(loder):\n",
        "    # move to gpu\n",
        "    x = x.type(dtype)\n",
        "    y = y.to('cuda')\n",
        "    #compute the ouput of the model\n",
        "    score = model(x)\n",
        "    # compute loss\n",
        "    loss = lss_fn(score, y)\n",
        "    #compute the gradiant and update the weights\n",
        "    optmizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optmizer.step()\n",
        "    # accomulate the loss and acc\n",
        "    epoch_loss += loss.item()\n",
        "    _, prediction = score.max(1)\n",
        "    epoch_acc += y.eq(prediction).sum().item() / y.size(0)\n",
        "    num_itr = idx+1\n",
        "  \n",
        "  epoch_loss /= num_itr\n",
        "  epoch_acc /= num_itr\n",
        "  \n",
        "  return epoch_loss, epoch_acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aISUhfQULNdg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def compte_acc(model, loder, lss_fn):\n",
        "  \n",
        "  if loder.dataset.train:\n",
        "    print(\"accurcy of Validation set\")\n",
        "  else:\n",
        "    print(\"accurcy of test set\")\n",
        "  \n",
        "  loss = 0.0\n",
        "  acc = 0.0\n",
        "  num_itr = 0\n",
        "  for idx, (x, y) in enumerate(loder):\n",
        "    x = x.type(dtype)\n",
        "    y = y.to('cuda')\n",
        "    score = model(x)\n",
        "    loss += lss_fn(score, y).item()\n",
        "    _, prid = score.max(1)\n",
        "    acc += (prid == y).sum().item() / y.size(0)\n",
        "    num_itr = idx+1\n",
        "    \n",
        "  acc /= num_itr\n",
        "  loss /= num_itr\n",
        "  \n",
        "  return loss, acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oAiYpBd5QncE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3160
        },
        "outputId": "643004a7-d2f4-477b-bb32-0c42ac2c28c5"
      },
      "cell_type": "code",
      "source": [
        "# loop of epochs \n",
        "\n",
        "for i in range(100):\n",
        "  scheduler.step()\n",
        "  %time tr_loss, tr_acc = train(VGG16_model, train_loder, lss_fun, optimizer, i)\n",
        "  print(f'traning loss {tr_loss} and traning acc {tr_acc}')\n",
        "  \n",
        "  val_loss, val_acc = compte_acc(VGG16_model, val_loder, lss_fun)\n",
        "  print(f'val loss {val_loss} and val acc {val_acc}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch number 0\n",
            "CPU times: user 2min 59s, sys: 22.4 s, total: 3min 21s\n",
            "Wall time: 3min 21s\n",
            "traning loss 0.5136792517362002 and traning acc 0.8226943788913437\n",
            "accurcy of Validation set\n",
            "val loss 0.511946901679039 and val acc 0.8318810096153846\n",
            "epoch number 1\n",
            "CPU times: user 2min 59s, sys: 22.3 s, total: 3min 21s\n",
            "Wall time: 3min 21s\n",
            "traning loss 0.5115465984798909 and traning acc 0.8238209856396866\n",
            "accurcy of Validation set\n",
            "val loss 0.5086415968835354 and val acc 0.8333834134615384\n",
            "epoch number 2\n",
            "CPU times: user 2min 59s, sys: 22.2 s, total: 3min 21s\n",
            "Wall time: 3min 21s\n",
            "traning loss 0.508135883366159 and traning acc 0.824392134464752\n",
            "accurcy of Validation set\n",
            "val loss 0.5063333623111248 and val acc 0.8345853365384616\n",
            "epoch number 3\n",
            "CPU times: user 2min 59s, sys: 22.1 s, total: 3min 21s\n",
            "Wall time: 3min 21s\n",
            "traning loss 0.5042048346436054 and traning acc 0.8249805432817835\n",
            "accurcy of Validation set\n",
            "val loss 0.5048054233193398 and val acc 0.8343599759615384\n",
            "epoch number 4\n",
            "CPU times: user 2min 59s, sys: 22.1 s, total: 3min 21s\n",
            "Wall time: 3min 21s\n",
            "traning loss 0.502625796720191 and traning acc 0.827552282084756\n",
            "accurcy of Validation set\n",
            "val loss 0.5028835125267506 and val acc 0.8343599759615384\n",
            "epoch number 5\n",
            "CPU times: user 2min 59s, sys: 22.3 s, total: 3min 21s\n",
            "Wall time: 3min 21s\n",
            "traning loss 0.5050019739346466 and traning acc 0.8254842212291624\n",
            "accurcy of Validation set\n",
            "val loss 0.5021326988935471 and val acc 0.8336087740384616\n",
            "epoch number 6\n",
            "CPU times: user 2min 58s, sys: 22.5 s, total: 3min 21s\n",
            "Wall time: 3min 21s\n",
            "traning loss 0.5007929442445541 and traning acc 0.8286867342839928\n",
            "accurcy of Validation set\n",
            "val loss 0.5023942478001118 and val acc 0.8304537259615384\n",
            "epoch number 7\n",
            "CPU times: user 2min 59s, sys: 21.9 s, total: 3min 21s\n",
            "Wall time: 3min 21s\n",
            "traning loss 0.49843823435101126 and traning acc 0.8289205287206266\n",
            "accurcy of Validation set\n",
            "val loss 0.5014503821730614 and val acc 0.8316556490384616\n",
            "epoch number 8\n",
            "CPU times: user 2min 59s, sys: 22.1 s, total: 3min 21s\n",
            "Wall time: 3min 21s\n",
            "traning loss 0.4986675643111645 and traning acc 0.8291558922474392\n",
            "accurcy of Validation set\n",
            "val loss 0.5011036023497581 and val acc 0.8348106971153846\n",
            "epoch number 9\n",
            "CPU times: user 2min 58s, sys: 22.4 s, total: 3min 21s\n",
            "Wall time: 3min 21s\n",
            "traning loss 0.4995083181727337 and traning acc 0.8282160072303676\n",
            "accurcy of Validation set\n",
            "val loss 0.5004931725561619 and val acc 0.8336087740384616\n",
            "epoch number 10\n",
            "CPU times: user 2min 59s, sys: 22.3 s, total: 3min 21s\n",
            "Wall time: 3min 21s\n",
            "traning loss 0.49963928568456567 and traning acc 0.8288703178349066\n",
            "accurcy of Validation set\n",
            "val loss 0.5003984086215496 and val acc 0.8336087740384616\n",
            "epoch number 11\n",
            "CPU times: user 2min 59s, sys: 22.4 s, total: 3min 21s\n",
            "Wall time: 3min 21s\n",
            "traning loss 0.5031312430185064 and traning acc 0.8265904298051818\n",
            "accurcy of Validation set\n",
            "val loss 0.5007764063775539 and val acc 0.8316556490384616\n",
            "epoch number 12\n",
            "CPU times: user 2min 59s, sys: 22.3 s, total: 3min 21s\n",
            "Wall time: 3min 21s\n",
            "traning loss 0.4977231359512937 and traning acc 0.8279790746133763\n",
            "accurcy of Validation set\n",
            "val loss 0.5008663050830364 and val acc 0.8345853365384616\n",
            "epoch number 13\n",
            "CPU times: user 2min 59s, sys: 22.1 s, total: 3min 21s\n",
            "Wall time: 3min 21s\n",
            "traning loss 0.49448836090981807 and traning acc 0.8278457019481824\n",
            "accurcy of Validation set\n",
            "val loss 0.5007897913455963 and val acc 0.8345853365384616\n",
            "epoch number 14\n",
            "CPU times: user 2min 59s, sys: 21.8 s, total: 3min 21s\n",
            "Wall time: 3min 21s\n",
            "traning loss 0.49777067353457755 and traning acc 0.8290178123117092\n",
            "accurcy of Validation set\n",
            "val loss 0.5007318146526814 and val acc 0.8355618990384616\n",
            "epoch number 15\n",
            "CPU times: user 2min 59s, sys: 21.8 s, total: 3min 21s\n",
            "Wall time: 3min 21s\n",
            "traning loss 0.4969339206542421 and traning acc 0.829705073810002\n",
            "accurcy of Validation set\n",
            "val loss 0.5006635673344135 and val acc 0.8355618990384616\n",
            "epoch number 16\n",
            "CPU times: user 2min 59s, sys: 21.6 s, total: 3min 21s\n",
            "Wall time: 3min 21s\n",
            "traning loss 0.4944699855603997 and traning acc 0.828666336111669\n",
            "accurcy of Validation set\n",
            "val loss 0.5006178840994835 and val acc 0.8345853365384616\n",
            "epoch number 17\n",
            "CPU times: user 2min 59s, sys: 21.9 s, total: 3min 21s\n",
            "Wall time: 3min 21s\n",
            "traning loss 0.49764163718211124 and traning acc 0.8280434073107049\n",
            "accurcy of Validation set\n",
            "val loss 0.5005419552326202 and val acc 0.8355618990384616\n",
            "epoch number 18\n",
            "CPU times: user 2min 58s, sys: 22.7 s, total: 3min 21s\n",
            "Wall time: 3min 21s\n",
            "traning loss 0.49764828636814346 and traning acc 0.8294869702751557\n",
            "accurcy of Validation set\n",
            "val loss 0.5004464872181416 and val acc 0.8355618990384616\n",
            "epoch number 19\n",
            "CPU times: user 2min 59s, sys: 22.4 s, total: 3min 21s\n",
            "Wall time: 3min 21s\n",
            "traning loss 0.49472674478438755 and traning acc 0.8286145561357703\n",
            "accurcy of Validation set\n",
            "val loss 0.500371266156435 and val acc 0.8336087740384616\n",
            "epoch number 20\n",
            "CPU times: user 2min 59s, sys: 22.2 s, total: 3min 21s\n",
            "Wall time: 3min 21s\n",
            "traning loss 0.49715618551866814 and traning acc 0.8297537156055433\n",
            "accurcy of Validation set\n",
            "val loss 0.5003427863121033 and val acc 0.8336087740384616\n",
            "epoch number 21\n",
            "CPU times: user 2min 58s, sys: 23.1 s, total: 3min 21s\n",
            "Wall time: 3min 21s\n",
            "traning loss 0.5001947786415837 and traning acc 0.8295983756778469\n",
            "accurcy of Validation set\n",
            "val loss 0.5003328435122967 and val acc 0.8336087740384616\n",
            "epoch number 22\n",
            "CPU times: user 2min 58s, sys: 22.7 s, total: 3min 21s\n",
            "Wall time: 3min 21s\n",
            "traning loss 0.49665246339753155 and traning acc 0.8290491941152842\n",
            "accurcy of Validation set\n",
            "val loss 0.5002170987427235 and val acc 0.8336087740384616\n",
            "epoch number 23\n",
            "CPU times: user 2min 58s, sys: 23.2 s, total: 3min 21s\n",
            "Wall time: 3min 21s\n",
            "traning loss 0.49690307431681663 and traning acc 0.8290539013858205\n",
            "accurcy of Validation set\n",
            "val loss 0.5002111196517944 and val acc 0.8336087740384616\n",
            "epoch number 24\n",
            "CPU times: user 2min 58s, sys: 23 s, total: 3min 21s\n",
            "Wall time: 3min 21s\n",
            "traning loss 0.4956762898839796 and traning acc 0.8296893829082145\n",
            "accurcy of Validation set\n",
            "val loss 0.5002073086798191 and val acc 0.8336087740384616\n",
            "epoch number 25\n",
            "CPU times: user 2min 57s, sys: 23.6 s, total: 3min 21s\n",
            "Wall time: 3min 21s\n",
            "traning loss 0.49606986402220266 and traning acc 0.8288954232777667\n",
            "accurcy of Validation set\n",
            "val loss 0.5001999773085117 and val acc 0.8336087740384616\n",
            "epoch number 26\n",
            "CPU times: user 2min 53s, sys: 27.9 s, total: 3min 21s\n",
            "Wall time: 3min 21s\n",
            "traning loss 0.49554339494779903 and traning acc 0.8287322378991766\n",
            "accurcy of Validation set\n",
            "val loss 0.5001997202634811 and val acc 0.8336087740384616\n",
            "epoch number 27\n",
            "CPU times: user 2min 57s, sys: 23.8 s, total: 3min 21s\n",
            "Wall time: 3min 21s\n",
            "traning loss 0.49795268199773746 and traning acc 0.8282536653946576\n",
            "accurcy of Validation set\n",
            "val loss 0.5001917779445648 and val acc 0.8336087740384616\n",
            "epoch number 28\n",
            "CPU times: user 2min 59s, sys: 22.1 s, total: 3min 21s\n",
            "Wall time: 3min 21s\n",
            "traning loss 0.4959896802124093 and traning acc 0.8296705538260696\n",
            "accurcy of Validation set\n",
            "val loss 0.5001855902373791 and val acc 0.8336087740384616\n",
            "epoch number 29\n",
            "CPU times: user 2min 59s, sys: 22.3 s, total: 3min 21s\n",
            "Wall time: 3min 21s\n",
            "traning loss 0.49901561754179374 and traning acc 0.8295073684474795\n",
            "accurcy of Validation set\n",
            "val loss 0.5001770630478859 and val acc 0.8336087740384616\n",
            "epoch number 30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GKdiHlFtSKrn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}